{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preditor de localização de proteinas ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6vvxKb1cuDieKz4GMvPBD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariacmartins/bioinformatica-disciplina/blob/main/Preditor_de_localiza%C3%A7%C3%A3o_de_proteinas_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyew6x3dJhKN",
        "outputId": "18d94766-5787-4b3a-f489-b240d985b512"
      },
      "source": [
        "!pip install biopython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/cd/0098eaff841850c01da928c7f509b72fd3e1f51d77b772e24de9e2312471/biopython-1.78-cp37-cp37m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggTHI4CiKXL_",
        "outputId": "f6e2393f-dad4-4e16-90f4-64dd0721e77b"
      },
      "source": [
        "#Obtendo os dados\n",
        "!wget -O membrane.fasta 'https://www.uniprot.org/uniprot/?query=taxonomy%3Abacteria+locations%3A%28location%3Amembrane%29&sort=score&format=fasta&limit=10000'\n",
        "!wget -O cytoplasm.fasta 'https://www.uniprot.org/uniprot/?query=taxonomy%3Abacteria+locations%3A%28location%3Acytoplasm%29&sort=score&format=fasta&limit=10000'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 16:11:47--  https://www.uniprot.org/uniprot/?query=taxonomy%3Abacteria+locations%3A%28location%3Amembrane%29&sort=score&format=fasta&limit=10000\n",
            "Resolving www.uniprot.org (www.uniprot.org)... 193.62.193.81, 128.175.245.202\n",
            "Connecting to www.uniprot.org (www.uniprot.org)|193.62.193.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 \n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘membrane.fasta’\n",
            "\n",
            "membrane.fasta          [      <=>           ]   5.68M   306KB/s    in 17s     \n",
            "\n",
            "2021-04-12 16:12:18 (345 KB/s) - ‘membrane.fasta’ saved [5952076]\n",
            "\n",
            "--2021-04-12 16:12:18--  https://www.uniprot.org/uniprot/?query=taxonomy%3Abacteria+locations%3A%28location%3Acytoplasm%29&sort=score&format=fasta&limit=10000\n",
            "Resolving www.uniprot.org (www.uniprot.org)... 128.175.245.202, 193.62.193.81\n",
            "Connecting to www.uniprot.org (www.uniprot.org)|128.175.245.202|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 \n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘cytoplasm.fasta’\n",
            "\n",
            "cytoplasm.fasta         [       <=>          ]   5.78M  3.96MB/s    in 1.5s    \n",
            "\n",
            "2021-04-12 16:12:25 (3.96 MB/s) - ‘cytoplasm.fasta’ saved [6062903]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7fLEqHFLefo"
      },
      "source": [
        "from Bio import SeqIO\n",
        "from Bio.SeqUtils import ProtParam\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5QoRYO6MD10"
      },
      "source": [
        "def compute_aa_composition(protein_sequence):\n",
        "  protein_analyzer = ProtParam.ProteinAnalysis(str(protein_sequence))\n",
        "  protein_data = protein_analyzer.get_amino_acids_percent()\n",
        "  return protein_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "XiHO1HfVNDhy",
        "outputId": "22131a5c-efff-4892-d722-0c00f0ddad03"
      },
      "source": [
        "#Construindo os dataframes com localização de proteínas - membrana e citoplasma\n",
        "df = pd.DataFrame()\n",
        "\n",
        "handle = open('membrane.fasta')\n",
        "parser = SeqIO.parse(handle, 'fasta')\n",
        "\n",
        "for record in parser:\n",
        "  protein_data = compute_aa_composition(record.seq)\n",
        "  protein_data['membrane'] = 1\n",
        "  df = df.append(protein_data, ignore_index=True)\n",
        "\n",
        "\n",
        "handle = open('cytoplasm.fasta')\n",
        "parser = SeqIO.parse(handle, 'fasta')\n",
        "\n",
        "for record in parser:\n",
        "  protein_data = compute_aa_composition(record.seq)\n",
        "  protein_data['membrane'] = 0\n",
        "  df = df.append(protein_data, ignore_index=True)\n",
        "\n",
        "df.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>P</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>Y</th>\n",
              "      <th>membrane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.308789</td>\n",
              "      <td>0.004751</td>\n",
              "      <td>0.047506</td>\n",
              "      <td>0.106888</td>\n",
              "      <td>0.014252</td>\n",
              "      <td>0.049881</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.033254</td>\n",
              "      <td>0.156770</td>\n",
              "      <td>0.045131</td>\n",
              "      <td>0.011876</td>\n",
              "      <td>0.026128</td>\n",
              "      <td>0.023753</td>\n",
              "      <td>0.047506</td>\n",
              "      <td>0.021378</td>\n",
              "      <td>0.052257</td>\n",
              "      <td>0.014252</td>\n",
              "      <td>0.019002</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.011876</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.072368</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.085526</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.085526</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.085526</td>\n",
              "      <td>0.046053</td>\n",
              "      <td>0.072368</td>\n",
              "      <td>0.032895</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.059211</td>\n",
              "      <td>0.032895</td>\n",
              "      <td>0.065789</td>\n",
              "      <td>0.046053</td>\n",
              "      <td>0.039474</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.039340</td>\n",
              "      <td>0.004230</td>\n",
              "      <td>0.075296</td>\n",
              "      <td>0.070643</td>\n",
              "      <td>0.055415</td>\n",
              "      <td>0.054569</td>\n",
              "      <td>0.009729</td>\n",
              "      <td>0.104907</td>\n",
              "      <td>0.076988</td>\n",
              "      <td>0.085871</td>\n",
              "      <td>0.014805</td>\n",
              "      <td>0.096870</td>\n",
              "      <td>0.024112</td>\n",
              "      <td>0.024958</td>\n",
              "      <td>0.019459</td>\n",
              "      <td>0.076988</td>\n",
              "      <td>0.051607</td>\n",
              "      <td>0.047377</td>\n",
              "      <td>0.006768</td>\n",
              "      <td>0.060068</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.143204</td>\n",
              "      <td>0.021845</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.016990</td>\n",
              "      <td>0.067961</td>\n",
              "      <td>0.131068</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>0.060680</td>\n",
              "      <td>0.036408</td>\n",
              "      <td>0.109223</td>\n",
              "      <td>0.041262</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>0.063107</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.026699</td>\n",
              "      <td>0.036408</td>\n",
              "      <td>0.063107</td>\n",
              "      <td>0.050971</td>\n",
              "      <td>0.033981</td>\n",
              "      <td>0.043689</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.111597</td>\n",
              "      <td>0.007659</td>\n",
              "      <td>0.050328</td>\n",
              "      <td>0.063457</td>\n",
              "      <td>0.020788</td>\n",
              "      <td>0.050328</td>\n",
              "      <td>0.016411</td>\n",
              "      <td>0.060175</td>\n",
              "      <td>0.025164</td>\n",
              "      <td>0.145514</td>\n",
              "      <td>0.021882</td>\n",
              "      <td>0.038293</td>\n",
              "      <td>0.033917</td>\n",
              "      <td>0.094092</td>\n",
              "      <td>0.066740</td>\n",
              "      <td>0.066740</td>\n",
              "      <td>0.055799</td>\n",
              "      <td>0.049234</td>\n",
              "      <td>0.008753</td>\n",
              "      <td>0.013129</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.110687</td>\n",
              "      <td>0.011450</td>\n",
              "      <td>0.053435</td>\n",
              "      <td>0.091603</td>\n",
              "      <td>0.019084</td>\n",
              "      <td>0.072519</td>\n",
              "      <td>0.026718</td>\n",
              "      <td>0.049618</td>\n",
              "      <td>0.015267</td>\n",
              "      <td>0.110687</td>\n",
              "      <td>0.015267</td>\n",
              "      <td>0.022901</td>\n",
              "      <td>0.041985</td>\n",
              "      <td>0.019084</td>\n",
              "      <td>0.099237</td>\n",
              "      <td>0.064885</td>\n",
              "      <td>0.038168</td>\n",
              "      <td>0.072519</td>\n",
              "      <td>0.022901</td>\n",
              "      <td>0.041985</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.061571</td>\n",
              "      <td>0.002123</td>\n",
              "      <td>0.076433</td>\n",
              "      <td>0.063694</td>\n",
              "      <td>0.029724</td>\n",
              "      <td>0.055202</td>\n",
              "      <td>0.016985</td>\n",
              "      <td>0.048832</td>\n",
              "      <td>0.065817</td>\n",
              "      <td>0.087049</td>\n",
              "      <td>0.012739</td>\n",
              "      <td>0.053079</td>\n",
              "      <td>0.036093</td>\n",
              "      <td>0.044586</td>\n",
              "      <td>0.042463</td>\n",
              "      <td>0.074310</td>\n",
              "      <td>0.076433</td>\n",
              "      <td>0.095541</td>\n",
              "      <td>0.016985</td>\n",
              "      <td>0.040340</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.101031</td>\n",
              "      <td>0.014433</td>\n",
              "      <td>0.035052</td>\n",
              "      <td>0.020619</td>\n",
              "      <td>0.092784</td>\n",
              "      <td>0.084536</td>\n",
              "      <td>0.020619</td>\n",
              "      <td>0.068041</td>\n",
              "      <td>0.028866</td>\n",
              "      <td>0.140206</td>\n",
              "      <td>0.024742</td>\n",
              "      <td>0.016495</td>\n",
              "      <td>0.041237</td>\n",
              "      <td>0.018557</td>\n",
              "      <td>0.035052</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.068041</td>\n",
              "      <td>0.080412</td>\n",
              "      <td>0.020619</td>\n",
              "      <td>0.026804</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.048110</td>\n",
              "      <td>0.010309</td>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.027491</td>\n",
              "      <td>0.127148</td>\n",
              "      <td>0.072165</td>\n",
              "      <td>0.017182</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.044674</td>\n",
              "      <td>0.158076</td>\n",
              "      <td>0.013746</td>\n",
              "      <td>0.030928</td>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.006873</td>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.089347</td>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.099656</td>\n",
              "      <td>0.017182</td>\n",
              "      <td>0.024055</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.084722</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>0.051389</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.026389</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.009722</td>\n",
              "      <td>0.069444</td>\n",
              "      <td>0.061111</td>\n",
              "      <td>0.105556</td>\n",
              "      <td>0.023611</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.036111</td>\n",
              "      <td>0.051389</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.068056</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.081944</td>\n",
              "      <td>0.006944</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          A         C         D  ...         W         Y  membrane\n",
              "0  0.308789  0.004751  0.047506  ...  0.002375  0.011876       1.0\n",
              "1  0.072368  0.006579  0.085526  ...  0.026316  0.026316       1.0\n",
              "2  0.039340  0.004230  0.075296  ...  0.006768  0.060068       1.0\n",
              "3  0.143204  0.021845  0.019417  ...  0.033981  0.043689       1.0\n",
              "4  0.111597  0.007659  0.050328  ...  0.008753  0.013129       1.0\n",
              "5  0.110687  0.011450  0.053435  ...  0.022901  0.041985       1.0\n",
              "6  0.061571  0.002123  0.076433  ...  0.016985  0.040340       1.0\n",
              "7  0.101031  0.014433  0.035052  ...  0.020619  0.026804       1.0\n",
              "8  0.048110  0.010309  0.037801  ...  0.017182  0.024055       1.0\n",
              "9  0.084722  0.004167  0.051389  ...  0.006944  0.027778       1.0\n",
              "\n",
              "[10 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed3N4ErKRGy3"
      },
      "source": [
        "X = df.drop(['membrane'], axis=1)\n",
        "y = df['membrane']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "QRMESJlRSXl5",
        "outputId": "d23997c7-90e5-48dc-cf7b-3baae3f36a0d"
      },
      "source": [
        "X"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>P</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.308789</td>\n",
              "      <td>0.004751</td>\n",
              "      <td>0.047506</td>\n",
              "      <td>0.106888</td>\n",
              "      <td>0.014252</td>\n",
              "      <td>0.049881</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.033254</td>\n",
              "      <td>0.156770</td>\n",
              "      <td>0.045131</td>\n",
              "      <td>0.011876</td>\n",
              "      <td>0.026128</td>\n",
              "      <td>0.023753</td>\n",
              "      <td>0.047506</td>\n",
              "      <td>0.021378</td>\n",
              "      <td>0.052257</td>\n",
              "      <td>0.014252</td>\n",
              "      <td>0.019002</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.011876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.072368</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.085526</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.085526</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.085526</td>\n",
              "      <td>0.046053</td>\n",
              "      <td>0.072368</td>\n",
              "      <td>0.032895</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.059211</td>\n",
              "      <td>0.032895</td>\n",
              "      <td>0.065789</td>\n",
              "      <td>0.046053</td>\n",
              "      <td>0.039474</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.026316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.039340</td>\n",
              "      <td>0.004230</td>\n",
              "      <td>0.075296</td>\n",
              "      <td>0.070643</td>\n",
              "      <td>0.055415</td>\n",
              "      <td>0.054569</td>\n",
              "      <td>0.009729</td>\n",
              "      <td>0.104907</td>\n",
              "      <td>0.076988</td>\n",
              "      <td>0.085871</td>\n",
              "      <td>0.014805</td>\n",
              "      <td>0.096870</td>\n",
              "      <td>0.024112</td>\n",
              "      <td>0.024958</td>\n",
              "      <td>0.019459</td>\n",
              "      <td>0.076988</td>\n",
              "      <td>0.051607</td>\n",
              "      <td>0.047377</td>\n",
              "      <td>0.006768</td>\n",
              "      <td>0.060068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.143204</td>\n",
              "      <td>0.021845</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.016990</td>\n",
              "      <td>0.067961</td>\n",
              "      <td>0.131068</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>0.060680</td>\n",
              "      <td>0.036408</td>\n",
              "      <td>0.109223</td>\n",
              "      <td>0.041262</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>0.063107</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.026699</td>\n",
              "      <td>0.036408</td>\n",
              "      <td>0.063107</td>\n",
              "      <td>0.050971</td>\n",
              "      <td>0.033981</td>\n",
              "      <td>0.043689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.111597</td>\n",
              "      <td>0.007659</td>\n",
              "      <td>0.050328</td>\n",
              "      <td>0.063457</td>\n",
              "      <td>0.020788</td>\n",
              "      <td>0.050328</td>\n",
              "      <td>0.016411</td>\n",
              "      <td>0.060175</td>\n",
              "      <td>0.025164</td>\n",
              "      <td>0.145514</td>\n",
              "      <td>0.021882</td>\n",
              "      <td>0.038293</td>\n",
              "      <td>0.033917</td>\n",
              "      <td>0.094092</td>\n",
              "      <td>0.066740</td>\n",
              "      <td>0.066740</td>\n",
              "      <td>0.055799</td>\n",
              "      <td>0.049234</td>\n",
              "      <td>0.008753</td>\n",
              "      <td>0.013129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.144737</td>\n",
              "      <td>0.010965</td>\n",
              "      <td>0.050439</td>\n",
              "      <td>0.074561</td>\n",
              "      <td>0.024123</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.019737</td>\n",
              "      <td>0.067982</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.015351</td>\n",
              "      <td>0.030702</td>\n",
              "      <td>0.032895</td>\n",
              "      <td>0.015351</td>\n",
              "      <td>0.070175</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.046053</td>\n",
              "      <td>0.094298</td>\n",
              "      <td>0.004386</td>\n",
              "      <td>0.019737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.015251</td>\n",
              "      <td>0.047930</td>\n",
              "      <td>0.076253</td>\n",
              "      <td>0.021786</td>\n",
              "      <td>0.089325</td>\n",
              "      <td>0.034858</td>\n",
              "      <td>0.080610</td>\n",
              "      <td>0.071895</td>\n",
              "      <td>0.067538</td>\n",
              "      <td>0.015251</td>\n",
              "      <td>0.056645</td>\n",
              "      <td>0.026144</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.028322</td>\n",
              "      <td>0.065359</td>\n",
              "      <td>0.069717</td>\n",
              "      <td>0.089325</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.085153</td>\n",
              "      <td>0.017467</td>\n",
              "      <td>0.045852</td>\n",
              "      <td>0.080786</td>\n",
              "      <td>0.019651</td>\n",
              "      <td>0.093886</td>\n",
              "      <td>0.026201</td>\n",
              "      <td>0.069869</td>\n",
              "      <td>0.069869</td>\n",
              "      <td>0.063319</td>\n",
              "      <td>0.010917</td>\n",
              "      <td>0.048035</td>\n",
              "      <td>0.032751</td>\n",
              "      <td>0.048035</td>\n",
              "      <td>0.037118</td>\n",
              "      <td>0.050218</td>\n",
              "      <td>0.069869</td>\n",
              "      <td>0.104803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.123620</td>\n",
              "      <td>0.011038</td>\n",
              "      <td>0.072848</td>\n",
              "      <td>0.041943</td>\n",
              "      <td>0.015453</td>\n",
              "      <td>0.103753</td>\n",
              "      <td>0.019868</td>\n",
              "      <td>0.057395</td>\n",
              "      <td>0.039735</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.046358</td>\n",
              "      <td>0.039735</td>\n",
              "      <td>0.037528</td>\n",
              "      <td>0.057395</td>\n",
              "      <td>0.028698</td>\n",
              "      <td>0.075055</td>\n",
              "      <td>0.108168</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.019868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.141079</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.085062</td>\n",
              "      <td>0.047718</td>\n",
              "      <td>0.012448</td>\n",
              "      <td>0.101660</td>\n",
              "      <td>0.020747</td>\n",
              "      <td>0.043568</td>\n",
              "      <td>0.022822</td>\n",
              "      <td>0.078838</td>\n",
              "      <td>0.012448</td>\n",
              "      <td>0.026971</td>\n",
              "      <td>0.045643</td>\n",
              "      <td>0.020747</td>\n",
              "      <td>0.072614</td>\n",
              "      <td>0.037344</td>\n",
              "      <td>0.074689</td>\n",
              "      <td>0.126556</td>\n",
              "      <td>0.006224</td>\n",
              "      <td>0.018672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              A         C         D  ...         V         W         Y\n",
              "0      0.308789  0.004751  0.047506  ...  0.019002  0.002375  0.011876\n",
              "1      0.072368  0.006579  0.085526  ...  0.105263  0.026316  0.026316\n",
              "2      0.039340  0.004230  0.075296  ...  0.047377  0.006768  0.060068\n",
              "3      0.143204  0.021845  0.019417  ...  0.050971  0.033981  0.043689\n",
              "4      0.111597  0.007659  0.050328  ...  0.049234  0.008753  0.013129\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "19995  0.144737  0.010965  0.050439  ...  0.094298  0.004386  0.019737\n",
              "19996  0.078431  0.015251  0.047930  ...  0.089325  0.000000  0.028322\n",
              "19997  0.085153  0.017467  0.045852  ...  0.104803  0.000000  0.026201\n",
              "19998  0.123620  0.011038  0.072848  ...  0.108168  0.006623  0.019868\n",
              "19999  0.141079  0.004149  0.085062  ...  0.126556  0.006224  0.018672\n",
              "\n",
              "[20000 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5jbDfSUSbja",
        "outputId": "19c8b1e1-c85c-4b65-df1f-2bb30e0cf0a6"
      },
      "source": [
        "y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1.0\n",
              "1        1.0\n",
              "2        1.0\n",
              "3        1.0\n",
              "4        1.0\n",
              "        ... \n",
              "19995    0.0\n",
              "19996    0.0\n",
              "19997    0.0\n",
              "19998    0.0\n",
              "19999    0.0\n",
              "Name: membrane, Length: 20000, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDFxXmIW2Z2D"
      },
      "source": [
        "### Comparando modelos de predição de localização subcelular de proteínas por Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1b-Hh74S4GE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiCPcTDfT808",
        "outputId": "3653a0f4-5eb1-43f5-b7e9-8491ca6f549f"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S21yIUKHUSDc",
        "outputId": "36c7bcec-0af2-468e-9dcc-4115e8dc27bf"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.79      0.83      2540\n",
            "         1.0       0.80      0.89      0.84      2460\n",
            "\n",
            "    accuracy                           0.84      5000\n",
            "   macro avg       0.84      0.84      0.84      5000\n",
            "weighted avg       0.84      0.84      0.84      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg48Q4QPXIwf",
        "outputId": "45abff1d-b908-4dd1-eb07-619a0193fa42"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model = MLPClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gEGNbIlXeNw",
        "outputId": "2615cf53-043d-4ac8-b38c-1905d685f2bc"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.92      0.93      2540\n",
            "         1.0       0.92      0.93      0.93      2460\n",
            "\n",
            "    accuracy                           0.93      5000\n",
            "   macro avg       0.93      0.93      0.93      5000\n",
            "weighted avg       0.93      0.93      0.93      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5zNBRN4X9UG",
        "outputId": "732b7387-1cd6-423c-f72e-e0b93aee9b0e"
      },
      "source": [
        "model = MLPClassifier(hidden_layer_sizes=(100, 50, 25))\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100, 50, 25), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2x-gP8sYPom",
        "outputId": "c17ea3f5-0e73-40ab-ffe9-c49c8e9d42fd"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.95      0.95      2540\n",
            "         1.0       0.95      0.95      0.95      2460\n",
            "\n",
            "    accuracy                           0.95      5000\n",
            "   macro avg       0.95      0.95      0.95      5000\n",
            "weighted avg       0.95      0.95      0.95      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EdmZ8l9Zco-",
        "outputId": "4a3f1a02-a589-4c94-9e30-a7a6369e57d3"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEMjbq-QZr-U",
        "outputId": "4c657476-ecaf-4cfd-c60f-c56cfc077a3a"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.91      0.91      2540\n",
            "         1.0       0.90      0.91      0.91      2460\n",
            "\n",
            "    accuracy                           0.91      5000\n",
            "   macro avg       0.91      0.91      0.91      5000\n",
            "weighted avg       0.91      0.91      0.91      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8BRJf_jbAUV",
        "outputId": "7ea498bb-f758-47aa-9cfb-a24a225dd3a0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjiCO50TbhwN",
        "outputId": "3b74b435-13a4-432b-93ee-44caad5b8062"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.93      0.94      2540\n",
            "         1.0       0.93      0.95      0.94      2460\n",
            "\n",
            "    accuracy                           0.94      5000\n",
            "   macro avg       0.94      0.94      0.94      5000\n",
            "weighted avg       0.94      0.94      0.94      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC6qYlzpcNLG",
        "outputId": "562b82de-31a8-4a96-e9d1-e1d4a0548154"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgngg8yUc_ap",
        "outputId": "65c55d78-27a0-447a-f5bc-ffb0508b628f"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.92      0.93      2540\n",
            "         1.0       0.92      0.94      0.93      2460\n",
            "\n",
            "    accuracy                           0.93      5000\n",
            "   macro avg       0.93      0.93      0.93      5000\n",
            "weighted avg       0.93      0.93      0.93      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}